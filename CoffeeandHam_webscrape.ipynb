{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CoffeeandHam_webscrape.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/crzaratech/CoffeeBytes/blob/temp/CoffeeandHam_webscrape.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfXEwWEdSb4Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        },
        "outputId": "9a9920da-6647-4ac2-f91c-71a1586ff0b1"
      },
      "source": [
        "#This will only be used for educational purposes and analysis. It will not be used for profiting of any kind. \n",
        "#what is webscraping? https://en.wikipedia.org/wiki/Web_scraping\n",
        "\n",
        "\n",
        "#https://www.crummy.com/software/BeautifulSoup/bs4/doc/\n",
        "#is a Python library for pulling data out of HTML and XML files.\n",
        "from bs4 import BeautifulSoup as soup\n",
        "#https://docs.python.org/3/library/urllib.request.html\n",
        "#we only want to use urlopen from the urllib library\n",
        "from urllib.request import urlopen as uReq\n",
        "\n",
        "#lets assing our url to a variable called \"myUrl\"\n",
        "myUrl = 'https://mcallen.craigslist.org/d/computers/search/sya'\n",
        "\n",
        "#calling urlopen. Open a conection and downloads the webpage\n",
        "OpenWebpage = uReq(myUrl)\n",
        "\n",
        "\n",
        "#content goes to the variable\n",
        "page_html = OpenWebpage.read()\n",
        "#caution. depending on size of webpage this might crash\n",
        "#we are only downloading the first page so we should be okay\n",
        "#print(page_html)\n",
        "\n",
        "#we close it once we are done reading it\n",
        "OpenWebpage.close()\n",
        "\n",
        "#calls the beautiful soup package\n",
        "#this parses the html into a more readable format\n",
        "#gets stored in a variable\n",
        "pageinSoup = soup(page_html, \"lxml\")\n",
        "#print(pageinSoup)\n",
        "\n",
        "#lets check if we are actually getting anytype of data from our URL!\n",
        "#this checks the parsed soup and goes to the first <p> tag that is foud\n",
        "#pageinSoup.p\n",
        "\n",
        "#now we want to get every item line by line, cleanly\n",
        "\n",
        "#if we analyze source we see that the class \"result row\" holds the entire item and belongs to the \"li\"\n",
        "#there is a function findAll, so we want to find all the lis with the class result row\n",
        "item = pageinSoup.find_all(\"li\",{\"class\" :\"result-row\"})\n",
        "\n",
        "exampleitem = item[0]\n",
        "print(exampleitem)\n",
        "\n",
        "\n",
        "#what are some usefull things that we can pull\n",
        "#lets try extracting the name of the item, the price and its direct link!\n",
        "\n",
        "#remember earlier in line 34 how we printed the <p> tag?\n",
        "#lets use that same method to extract data\n",
        "\n",
        "\n",
        "item_title = exampleitem.p.a.text\n",
        "\n",
        "#getting the price is a little tricky since there seems to be two price classes\n",
        "#not all of the items have the price at the top left\n",
        "#it looks like we have to find the correct one. Hint: it is in the second span tag\n",
        "#lets take a look at the documentatin and see if there is anything that could help us out!\n",
        "#https://www.crummy.com/software/BeautifulSoup/bs4/doc/#find\n",
        "#item_price = \n",
        "\n",
        "#item_link =\n",
        "\n",
        "print(item_title)\n",
        "\n",
        "\n",
        "#great we were able to pull out the information for the first element\n",
        "#what can we use to pull every item in the webpage?\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<li class=\"result-row\" data-pid=\"7001617056\">\n",
            "<a class=\"result-image gallery\" data-ids=\"1:01515_kU2KrpGcXFX,1:00X0X_g1e9SPQXD8P,1:00T0T_6SrATuV8sFo,1:01212_9b2BFsK1DIg,1:00u0u_huB6iOcX4w8\" href=\"https://mcallen.craigslist.org/sys/d/san-juan-macbook-pro-13-inch-with-case/7001617056.html\">\n",
            "<span class=\"result-price\">$250</span>\n",
            "</a>\n",
            "<p class=\"result-info\">\n",
            "<span class=\"icon icon-star\" role=\"button\">\n",
            "<span class=\"screen-reader-text\">favorite this post</span>\n",
            "</span>\n",
            "<time class=\"result-date\" datetime=\"2019-10-17 14:10\" title=\"Thu 17 Oct 02:10:57 PM\">Oct 17</time>\n",
            "<a class=\"result-title hdrlnk\" data-id=\"7001617056\" href=\"https://mcallen.craigslist.org/sys/d/san-juan-macbook-pro-13-inch-with-case/7001617056.html\">MacBook Pro 13 inch with case</a>\n",
            "<span class=\"result-meta\">\n",
            "<span class=\"result-price\">$250</span>\n",
            "<span class=\"result-tags\">\n",
            "<span class=\"pictag\">pic</span>\n",
            "</span>\n",
            "<span class=\"banish icon icon-trash\" role=\"button\">\n",
            "<span class=\"screen-reader-text\">hide this posting</span>\n",
            "</span>\n",
            "<span aria-hidden=\"true\" class=\"unbanish icon icon-trash red\" role=\"button\"></span>\n",
            "<a class=\"restore-link\" href=\"#\">\n",
            "<span class=\"restore-narrow-text\">restore</span>\n",
            "<span class=\"restore-wide-text\">restore this posting</span>\n",
            "</a>\n",
            "</span>\n",
            "</p>\n",
            "</li>\n",
            "MacBook Pro 13 inch with case\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAjX5muzWZ8l",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}